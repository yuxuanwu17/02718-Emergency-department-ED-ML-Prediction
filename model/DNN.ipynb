{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the feature selected data frame via mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534730, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esi</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "      <th>lang</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>employstatus</th>\n",
       "      <th>insurance_status</th>\n",
       "      <th>arrivalmode</th>\n",
       "      <th>previousdispo</th>\n",
       "      <th>...</th>\n",
       "      <th>meds_analgesics</th>\n",
       "      <th>meds_antiplateletdrugs</th>\n",
       "      <th>meds_cardiacdrugs</th>\n",
       "      <th>meds_cardiovascular</th>\n",
       "      <th>meds_diuretics</th>\n",
       "      <th>meds_elect/caloric/h2o</th>\n",
       "      <th>meds_gastrointestinal</th>\n",
       "      <th>meds_psychotherapeuticdrugs</th>\n",
       "      <th>meds_vitamins</th>\n",
       "      <th>disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   esi  age  ethnicity  race  lang  maritalstatus  employstatus  \\\n",
       "0    4   40          1     8     1              8             2   \n",
       "1    4   66          1     4     1              5             3   \n",
       "2    2   66          1     4     1              5             3   \n",
       "3    2   66          1     4     1              5             3   \n",
       "4    3   84          1     5     2             10             6   \n",
       "\n",
       "   insurance_status  arrivalmode  previousdispo  ...  meds_analgesics  \\\n",
       "0                 4            6              7  ...                0   \n",
       "1                 1            2              7  ...                0   \n",
       "2                 1            6              3  ...                0   \n",
       "3                 1            2              3  ...                0   \n",
       "4                 3            6              3  ...                0   \n",
       "\n",
       "   meds_antiplateletdrugs  meds_cardiacdrugs  meds_cardiovascular  \\\n",
       "0                       0                  0                    0   \n",
       "1                       0                  0                    0   \n",
       "2                       0                  0                    0   \n",
       "3                       0                  0                    0   \n",
       "4                       0                  0                    2   \n",
       "\n",
       "   meds_diuretics  meds_elect/caloric/h2o  meds_gastrointestinal  \\\n",
       "0               0                       0                      0   \n",
       "1               0                       0                      0   \n",
       "2               0                       0                      0   \n",
       "3               0                       0                      0   \n",
       "4               1                       2                      2   \n",
       "\n",
       "   meds_psychotherapeuticdrugs  meds_vitamins  disposition  \n",
       "0                            0              0            2  \n",
       "1                            0              0            2  \n",
       "2                            0              0            2  \n",
       "3                            0              0            2  \n",
       "4                            0              1            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(33)\n",
    "df = pd.read_csv(\"../data/featureSelectedAllDataWithY.csv\")\n",
    "# df = pd.read_csv(\"../data/Cleaned_dat_encoded.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the label to 0,1 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         1\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         0\n",
      "         ..\n",
      "534725    0\n",
      "534726    0\n",
      "534727    1\n",
      "534728    0\n",
      "534729    0\n",
      "Name: disposition, Length: 534730, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['disposition'].replace(1,0,inplace=True)\n",
    "df['disposition'].replace(2,1,inplace=True)\n",
    "\n",
    "print(df['disposition'])\n",
    "## Split the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "y_train = training_data['disposition']\n",
    "y_test = testing_data['disposition']\n",
    "X_train = StandardScaler().fit_transform(training_data.drop(\"disposition\",axis = 1))\n",
    "X_test = StandardScaler().fit_transform(testing_data.drop(\"disposition\",axis = 1))\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "# y_train = np.array(y_train)[:100]\n",
    "# y_test = np.array(y_test)[:10]\n",
    "# X_train = np.array(X_train)[:100,]\n",
    "# X_test = np.array(X_test)[:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Dense(30, activation='relu',input_shape=(20,)),\n",
    "        Dense(30, activation='relu'),\n",
    "        Dense(30, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy' ,weighted_metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with parameters in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 427784 samples\n",
      "Epoch 1/30\n",
      "427784/427784 [==============================] - 11s 26us/sample - loss: 0.2526 - accuracy: 0.8023\n",
      "Epoch 2/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2472 - accuracy: 0.8077\n",
      "Epoch 3/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2462 - accuracy: 0.8088\n",
      "Epoch 4/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2451 - accuracy: 0.8104\n",
      "Epoch 5/30\n",
      "427784/427784 [==============================] - 11s 26us/sample - loss: 0.2436 - accuracy: 0.8117\n",
      "Epoch 6/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2428 - accuracy: 0.8130\n",
      "Epoch 7/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2424 - accuracy: 0.8132\n",
      "Epoch 8/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2422 - accuracy: 0.8137\n",
      "Epoch 9/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2420 - accuracy: 0.8138\n",
      "Epoch 10/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2418 - accuracy: 0.8139\n",
      "Epoch 11/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2417 - accuracy: 0.8140\n",
      "Epoch 12/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2417 - accuracy: 0.8135\n",
      "Epoch 13/30\n",
      "427784/427784 [==============================] - 10s 23us/sample - loss: 0.2415 - accuracy: 0.8141\n",
      "Epoch 14/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2415 - accuracy: 0.8145\n",
      "Epoch 15/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2415 - accuracy: 0.8140\n",
      "Epoch 16/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2413 - accuracy: 0.8141\n",
      "Epoch 17/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2414 - accuracy: 0.8143\n",
      "Epoch 18/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2415 - accuracy: 0.8145\n",
      "Epoch 19/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2415 - accuracy: 0.8142\n",
      "Epoch 20/30\n",
      "427784/427784 [==============================] - 10s 25us/sample - loss: 0.2415 - accuracy: 0.8143\n",
      "Epoch 21/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2415 - accuracy: 0.8144\n",
      "Epoch 22/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2416 - accuracy: 0.8141\n",
      "Epoch 23/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2416 - accuracy: 0.8144\n",
      "Epoch 24/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2416 - accuracy: 0.8137\n",
      "Epoch 25/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2415 - accuracy: 0.8143\n",
      "Epoch 26/30\n",
      "427784/427784 [==============================] - 11s 25us/sample - loss: 0.2416 - accuracy: 0.8145\n",
      "Epoch 27/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2416 - accuracy: 0.8145\n",
      "Epoch 28/30\n",
      "427784/427784 [==============================] - 10s 24us/sample - loss: 0.2417 - accuracy: 0.8145\n",
      "Epoch 29/30\n",
      "427784/427784 [==============================] - 13s 30us/sample - loss: 0.2417 - accuracy: 0.8143\n",
      "Epoch 30/30\n",
      "427784/427784 [==============================] - 12s 28us/sample - loss: 0.2418 - accuracy: 0.8142\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "[[25447  7388]\n",
      " [10675 63436]]\n",
      "0.8311016774820937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "np.random.seed(52)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow_core.python.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# batch_size = best_clf.best_params_['batch_size']\n",
    "# epochs = best_clf.best_params_['epochs']\n",
    "# optimizer = best_clf.best_params_['optimizer']\n",
    "\n",
    "## Identified the results\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "optimizer = 'RMSprop'\n",
    "\n",
    "class_weight ={\n",
    "    1:0.445,\n",
    "    0:1\n",
    "}\n",
    "\n",
    "clf = create_model(optimizer)\n",
    "history = clf.fit(X_train, y_train,batch_size=batch_size,epochs=epochs,class_weight=class_weight)\n",
    "clf.save(\"dnn.h5\")\n",
    "# clf.fit(X_train, y_train,batch_size=batch_size,epochs=epochs)\n",
    "y_pred = clf.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "mylist = []\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "mylist.append(ac)\n",
    "print(cm)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the matrix results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+--------+-----------+--------+--------+\n",
      "| Accuracy | auROC  | auPRC  | recall | precision |   f1   |  MCC   |\n",
      "+----------+--------+--------+--------+-----------+--------+--------+\n",
      "|  0.8311  | 0.9035 | 0.9508 | 0.856  |   0.8957  | 0.8754 | 0.6154 |\n",
      "+----------+--------+--------+--------+-----------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from prettytable import PrettyTable\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "MCCs = []\n",
    "auROCs = []\n",
    "auPRCs = []\n",
    "\n",
    "accuracy_scores.append(accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "f1_scores.append(f1_score(y_true=y_test, y_pred=y_pred))\n",
    "recall_scores.append(recall_score(y_true=y_test, y_pred=y_pred))\n",
    "precision_scores.append(precision_score(y_true=y_test, y_pred=y_pred))\n",
    "MCCs.append(matthews_corrcoef(y_true=y_test, y_pred=y_pred))\n",
    "auROCs.append(roc_auc_score(y_true=y_test, y_score=clf.predict(X_test)))\n",
    "auPRCs.append(average_precision_score(y_true=y_test,  y_score=clf.predict(X_test)))\n",
    "\n",
    "table = PrettyTable()\n",
    "column_names = ['Accuracy', 'auROC', 'auPRC', 'recall', 'precision', 'f1', 'MCC']\n",
    "table.add_column(column_names[0], np.round(accuracy_scores, 4))\n",
    "table.add_column(column_names[1], np.round(auROCs, 4))\n",
    "table.add_column(column_names[2], np.round(auPRCs, 4))\n",
    "table.add_column(column_names[3], np.round(recall_scores, 4))\n",
    "table.add_column(column_names[4], np.round(precision_scores, 4))\n",
    "table.add_column(column_names[5], np.round(f1_scores, 4))\n",
    "table.add_column(column_names[6], np.round(MCCs, 4))\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Grid Search for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [16, 32, 64]\n",
    "epochs = [20, 50, 80, 110]\n",
    "optimizer = ['SGD', 'Adam','RMSprop']\n",
    "param_grid = dict(batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_clf = clf.fit(X_train, y_train)np.random.seed(52)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow_core.python.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# create model\n",
    "model =KerasClassifier(build_fn=create_model,verbose=0)\n",
    "\n",
    "## add the compile method for the neural network\n",
    "\n",
    "clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=5,n_jobs=-1)\n",
    "# clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=5,n_jobs=-1)\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best cross validation accuracy: {:.2f}\".format(best_clf.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(best_clf.score(X_test,y_test)))\n",
    "print(\"Best parameters: {}\".format(best_clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reason for no outputs:\n",
    "\n",
    "This grid search method would cost a whole day to generate the best hyperparameters. So we recorded the hyperparameters, but once a time, I incidently run this block again, so the output is missing. So we would not run this grid search again and use the returned parameters to train the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (proj4CM)",
   "language": "python",
   "name": "pycharm-f3dbbc4a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
