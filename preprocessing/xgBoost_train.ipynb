{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534730, 584)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   dep_name  esi  age  gender  ethnicity  race  lang  religion  maritalstatus  \\\n0         2    4   40       2          1     8     1         9              8   \n1         2    4   66       2          1     4     1        11              5   \n2         2    2   66       2          1     4     1        11              5   \n3         3    2   66       2          1     4     1        11              5   \n4         3    3   84       1          1     5     2        11             10   \n\n   employstatus  ...  cc_vaginaldischarge  cc_vaginalpain  cc_weakness  \\\n0             2  ...                    0               0            0   \n1             3  ...                    0               0            0   \n2             3  ...                    0               0            0   \n3             3  ...                    0               0            0   \n4             6  ...                    0               0            0   \n\n   cc_wheezing  cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n0            0                      0              0                  0   \n1            0                      0              0                  0   \n2            0                      0              0                  0   \n3            0                      0              0                  0   \n4            0                      0              0                  0   \n\n   cc_woundre-evaluation  cc_wristinjury  cc_wristpain  \n0                      0               0             0  \n1                      0               0             0  \n2                      0               0             0  \n3                      0               0             0  \n4                      0               0             0  \n\n[5 rows x 584 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dep_name</th>\n      <th>esi</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>ethnicity</th>\n      <th>race</th>\n      <th>lang</th>\n      <th>religion</th>\n      <th>maritalstatus</th>\n      <th>employstatus</th>\n      <th>...</th>\n      <th>cc_vaginaldischarge</th>\n      <th>cc_vaginalpain</th>\n      <th>cc_weakness</th>\n      <th>cc_wheezing</th>\n      <th>cc_withdrawal-alcohol</th>\n      <th>cc_woundcheck</th>\n      <th>cc_woundinfection</th>\n      <th>cc_woundre-evaluation</th>\n      <th>cc_wristinjury</th>\n      <th>cc_wristpain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>4</td>\n      <td>40</td>\n      <td>2</td>\n      <td>1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>9</td>\n      <td>8</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4</td>\n      <td>66</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>11</td>\n      <td>5</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>66</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>11</td>\n      <td>5</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2</td>\n      <td>66</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>11</td>\n      <td>5</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>3</td>\n      <td>84</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>11</td>\n      <td>10</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 584 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(33)\n",
    "# df = pd.read_csv(\"../data/featureSelectedAllDataWithY.csv\")\n",
    "df = pd.read_csv(\"../data/Cleaned_dat_encoded.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples: 427784\n",
      "No. of testing examples: 106946\n"
     ]
    }
   ],
   "source": [
    "## Split the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=25)\n",
    "\n",
    "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
    "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "y_train = training_data['disposition']\n",
    "y_test = testing_data['disposition']\n",
    "X_train = StandardScaler().fit_transform(training_data.drop(\"disposition\",axis = 1))\n",
    "X_test = StandardScaler().fit_transform(testing_data.drop(\"disposition\",axis = 1))\n",
    "\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)\n",
    "# X_train = np.array(X_train)\n",
    "# X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)[:100]\n",
    "y_test = np.array(y_test)[:10]\n",
    "X_train = np.array(X_train)[:100,]\n",
    "X_test = np.array(X_test)[:10,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuxuan/opt/anaconda3/envs/dp3.7/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:13:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-ad883da810ed>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmy_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mXGBClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.05\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# Add silent=True to avoid printing out updates with each cycle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mmy_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/dp3.7/lib/python3.7/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    420\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    421\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 422\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    423\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    424\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/dp3.7/lib/python3.7/site-packages/xgboost/sklearn.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m    913\u001B[0m                               \u001B[0mevals_result\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mevals_result\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfeval\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m                               \u001B[0mverbose_eval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxgb_model\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mxgb_model\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 915\u001B[0;31m                               callbacks=callbacks)\n\u001B[0m\u001B[1;32m    916\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobjective\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mxgb_options\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"objective\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/dp3.7/lib/python3.7/site-packages/xgboost/training.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001B[0m\n\u001B[1;32m    233\u001B[0m                           \u001B[0mevals_result\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mevals_result\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m                           \u001B[0mmaximize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximize\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 235\u001B[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001B[0m\u001B[1;32m    236\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mbst\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/dp3.7/lib/python3.7/site-packages/xgboost/training.py\u001B[0m in \u001B[0;36m_train_internal\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001B[0m\n\u001B[1;32m    100\u001B[0m         \u001B[0;31m# Skip the first update if it is a recovery step.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mversion\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m             \u001B[0mbst\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m             \u001B[0mbst\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_rabit_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m             \u001B[0mversion\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/dp3.7/lib/python3.7/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[1;32m   1280\u001B[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001B[1;32m   1281\u001B[0m                                                     \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_int\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1282\u001B[0;31m                                                     dtrain.handle))\n\u001B[0m\u001B[1;32m   1283\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1284\u001B[0m             \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "my_model = XGBClassifier(n_estimators=1000, learning_rate=0.05,n_jobs=6)\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "my_model.fit(X_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = my_model.predict(X_test)\n",
    "# Making Confusion Matrix and calculating accuracy score\n",
    "\n",
    "mylist = []\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "mylist.append(ac)\n",
    "print(cm)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "list1 = []\n",
    "for estimators in range(10,30,1):\n",
    "    classifier = XGBClassifier(n_estimators = estimators, max_depth=12, subsample=0.7)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    list1.append(accuracy_score(y_test,y_pred))\n",
    "#print(mylist)\n",
    "plt.plot(list(range(10,30,1)), list1)\n",
    "plt.show()\n",
    "\n",
    "xgb.plot_importance(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(33)\n",
    "# df = pd.read_csv(\"../data/featureSelectedAllDataWithY.csv\")\n",
    "df = pd.read_csv(\"../data/Cleaned_dat_encoded.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Split the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=25,shuffle=True)\n",
    "\n",
    "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
    "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "y_train = training_data['disposition']\n",
    "y_test = testing_data['disposition']\n",
    "X_train = StandardScaler().fit_transform(training_data.drop(\"disposition\",axis = 1))\n",
    "X_test = StandardScaler().fit_transform(testing_data.drop(\"disposition\",axis = 1))\n",
    "\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)\n",
    "# X_train = np.array(X_train)\n",
    "# X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)[:100]\n",
    "y_test = np.array(y_test)[:10]\n",
    "X_train = np.array(X_train)[:100,]\n",
    "X_test = np.array(X_test)[:10,]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(n_estimators=1000, learning_rate=0.05,n_jobs=6)\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "clf.fit(X_train, y_train, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "# Making Confusion Matrix and calculating accuracy score\n",
    "\n",
    "mylist = []\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "mylist.append(ac)\n",
    "print(cm)\n",
    "print(ac)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}